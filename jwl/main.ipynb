{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_pickle('products')\n",
    "priors = pd.read_pickle('priors')\n",
    "users = pd.read_pickle('users')\n",
    "userXproduct = pd.read_pickle('userXproduct')\n",
    "df_temp = pd.read_pickle('df_temp')\n",
    "df_train = pd.read_pickle('df_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_fun(labels, preds):\n",
    "    labels = labels.split(' ')\n",
    "    preds = preds.split(' ')\n",
    "    rr = (np.intersect1d(labels, preds))\n",
    "    precision = np.float(len(rr)) / len(preds)\n",
    "    recall = np.float(len(rr)) / len(labels)\n",
    "    try:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return (precision, recall, 0.0)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一些辅助函数 为了交叉验证 需要把同一订单号的 物品 合为一个\n",
    "def get_liststr(df_test):\n",
    "    n=1\n",
    "    for row in df_test:\n",
    "        if n==1:\n",
    "            temp=str(row)\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + str(row)\n",
    "    return  temp\n",
    "\n",
    "def get_liststr1(df_test):\n",
    "    n=1\n",
    "    for row in df_test.split(' '):\n",
    "        if n==1:\n",
    "            temp=row\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + row\n",
    "    return  temp\n",
    "#把预测结果 通过阈值 挑选出来 放入一个字符串中 ‘product1 2 3 4···’\n",
    "def get_pred_results(df_test,thrshold=0.22):\n",
    "    TRESHOLD = thrshold  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "    d = dict()\n",
    "    for row in df_test.itertuples():\n",
    "        if row.pred > TRESHOLD:\n",
    "            try:\n",
    "                d[row.order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                d[row.order_id] = str(row.product_id)\n",
    "\n",
    "    for order in df_test.order_id:\n",
    "        if order not in d:\n",
    "            d[order] = 'None'\n",
    "\n",
    "    sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "    sub.reset_index(inplace=True)\n",
    "    sub.columns = ['order_id', 'products']\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(df_train['labels'],dtype=pd.Series)\n",
    "df_train.drop(['labels'],axis=1,inplace=True)\n",
    "\n",
    "f_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_average_basket',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n",
    "\n",
    "\n",
    "\n",
    "#lgb.plot_importance(bst, figsize=(9,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fscore(df,bst,alpha):\n",
    "    df['pred'] = bst.predict(df[f_to_use])\n",
    "    train_pred=get_pred_results(df,thrshold=alpha)\n",
    "    #合表\n",
    "    train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "    #求F1结果表\n",
    "    res = list()\n",
    "    for entry in train_pred1.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    return res['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fscore_xgb(df,bst,alpha):\n",
    "    d_d=xgb.DMatrix(df[f_to_use])\n",
    "    df['pred'] = bst.predict(d_d)\n",
    "    train_pred=get_pred_results(df,thrshold=alpha)\n",
    "    #合表\n",
    "    train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "    #求F1结果表\n",
    "    res = list()\n",
    "    for entry in train_pred1.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    return res['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1: train:0.3864333011521617, test:0.3852574104797039\n",
      "* 2: train:0.3879747943099971, test:0.38371769833014324\n",
      "* 3: train:0.3883149779286648, test:0.38347921830055154\n",
      "ALL: test ALL： 0.387574357797\n",
      "cost time:165.48224068095442\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#先使用最简单的k-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 98\n",
    "kf=KFold(n_splits=3)    # 定义分成几个组\n",
    "list_f1=[]\n",
    "list_f2=[]\n",
    "num=1\n",
    "#clf=LGBMClassifier(objective='binary', boosting_type='gbdt')\n",
    "#决定采用手动cv  因为需要了利用合表才能得到F1 传统方法不可以 数组合表 太可怕···\n",
    "#把数组变成切边的形式  即可\n",
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "\n",
    "for train_index,test_index in kf.split(df_train, labels):\n",
    "    \n",
    "    #train_max=train_index.max()\n",
    "    #train_min=train_index.min()\n",
    "    test_max=test_index.max()+1\n",
    "    test_min=test_index.min()\n",
    "    X_test=df_train[test_min:test_max]\n",
    "    X_train=df_train.drop(test_index)\n",
    "    #X_train,X_test=data_train[train_index],data_train[test_index]\n",
    "    y_train,y_test=labels[train_index],labels[test_index]   \n",
    "    d_train = lgb.Dataset(X_train[f_to_use],\n",
    "                      label=y_train,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "    bst = lgb.train(params, d_train, ROUNDS)\n",
    "    a=fscore(X_train,bst,0.22)\n",
    "    b=fscore(X_test,bst,0.22)\n",
    "    list_f1.append(a)\n",
    "    list_f2.append(b)\n",
    "    print('* {}: train:{}, test:{}'.format(num,a,b))\n",
    "    num+=1\n",
    "    \n",
    "print('ALL:train:{} test:{}'.format(np.mean(list_f1),np.mean(list_f2)))\n",
    "end = timeit.default_timer()\n",
    "print('cost time:'+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cv :-) long time```\n",
      "* 1: train:0.3898881358325812, test:0.3859023167431283\n",
      "* 2: train:0.39209670668587865, test:0.3845590343301159\n",
      "* 3: train:0.39179431983115826, test:0.38377544466027075\n",
      "ALL:train:0.39125972078320603 test:0.3847455985778383\n",
      "cost time:802.6681804358959\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#先使用最简单的k-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "params_xgb ={\n",
    "  \"objective\"  : \"reg:logistic\",\n",
    "  \"eval_metric\"   : \"logloss\",\n",
    "  \"eta\"    :0.1,\n",
    "  \"max_depth\"   : 9,\n",
    "  \"min_child_weight\"  : 9,\n",
    "  \"gamma\"             : 0.70,\n",
    "  \"subsample\"          : 0.78,\n",
    "  \"colsample_bytree\"    : 0.95,\n",
    "  \"alpha\"             : 2e-05,\n",
    "  \"lambda\"            : 10\n",
    "        }\n",
    "kf=KFold(n_splits=3)    # 定义分成几个组\n",
    "list_f1=[]\n",
    "list_f2=[]\n",
    "num=1\n",
    "\n",
    "#clf=LGBMClassifier(objective='binary', boosting_type='gbdt')\n",
    "#决定采用手动cv  因为需要了利用合表才能得到F1 传统方法不可以 数组合表 太可怕···\n",
    "#把数组变成切边的形式  即可\n",
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "print('start cv :-) long time```')\n",
    "for train_index,test_index in kf.split(df_train, labels):\n",
    "    \n",
    "    test_max=test_index.max()+1\n",
    "    test_min=test_index.min()\n",
    "    X_test=df_train[test_min:test_max]\n",
    "    X_train=df_train.drop(test_index)\n",
    "    y_train,y_test=labels[train_index],labels[test_index]   \n",
    "    d_train = xgb.DMatrix(X_train[f_to_use],\n",
    "                      label=y_train)\n",
    "    \n",
    "    bst = xgb.train(params_xgb, d_train, ROUNDS)\n",
    "    a=fscore_xgb(X_train,bst,0.22)\n",
    "    b=fscore_xgb(X_test,bst,0.22)\n",
    "    list_f1.append(a)\n",
    "    list_f2.append(b)\n",
    "    print('* {}: train:{}, test:{}'.format(num,a,b))\n",
    "    num+=1\n",
    "    \n",
    "print('ALL:train:{} test:{}'.format(np.mean(list_f1),np.mean(list_f2)))\n",
    "end = timeit.default_timer()\n",
    "print('cost time:'+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d_train\n",
    "del X_test\n",
    "del X_train\n",
    "del y_train\n",
    "del y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build candidates list for test ###\n",
    "\n",
    "#前面搞好了 \n",
    "df_test = pd.read_pickle('df_test')\n",
    "#df_test, _ = features(test_orders)\n",
    "\n",
    "#clf.fit(df_train[f_to_use],labels)\n",
    "d_train = xgb.DMatrix(df_train[f_to_use],label=labels)\n",
    "d_d=xgb.DMatrix(df_test[f_to_use])   \n",
    "\n",
    "bst = xgb.train(params_xgb, d_train, ROUNDS)\n",
    "df_test['pred'] = bst.predict(d_d)\n",
    "\n",
    "sub=get_pred_results(df_test,0.22)\n",
    "#sub.to_csv('sub.csv', index=False)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "sub.to_csv('xgb_results_{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
